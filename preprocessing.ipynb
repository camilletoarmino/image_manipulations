{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(path, img, output_dir):\n",
    "    \"\"\"Binarize and remove background\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : arr\n",
    "        Image data\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    thresh_img : arr\n",
    "        Processed image\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # read in image\n",
    "    img_path = path+img\n",
    "    img = cv2.imread(img_path)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "    # Remove noise with bilateral filter (effective in noise removal while keeping edges sharp)\n",
    "    gray_img_filt = cv2.bilateralFilter(gray_img, d=7, sigmaColor=75, sigmaSpace=75)\n",
    "    # Remove shadows from image  by blurring image and subtracting from non-blurred image\n",
    "    dilated_img = cv2.dilate(gray_img_filt, kernel=np.ones((20, 20), np.uint8))\n",
    "    blur_img = cv2.medianBlur(dilated_img, ksize=21)\n",
    "    diff_img = 255 - cv2.absdiff(gray_img_filt, blur_img)\n",
    "    thresh_val = 0\n",
    "    max_value = 255\n",
    "    # Apply Otsu Binarization, which searches for a threshold based on the local minima in a\n",
    "    # bi-modal histogram\n",
    "    ret, thresh_img = cv2.threshold(diff_img, thresh=thresh_val, maxval=max_value, type=cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(thresh_img, cmap='Greys_r')\n",
    "    #plt.imshow(thresh_img)\n",
    "    # plt.show()\n",
    "    \n",
    "    # save image\n",
    "    save_filename = output_dir+file\n",
    "    cv2.imwrite(save_filename, thresh_img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:00<00:00, 246.53it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALoAAADnCAYAAACpHkzYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAEWklEQVR4nO3c0VLqSBRA0Wbq/v8vM09OoeYOCSJ0Z6/1ZOkL1WyPh0S4XK/XAWf3z7sfALyC0EkQOglCJ0HoJPy583OXZFjNZeubJjoJQidB6CQInQShkyB0EoROgtBJEDoJQuepLpfNG5NvJ3QS7v2vC+xyO8k/vp7p3WsmOglCJ0HoJNjR+ZFZr7J8ZaKTIHQShM6vmWmtETq/apbYhU6Cqy473U6mme74vdMs03oPE32HlZ5Qtgn9DpGfg9BJsKNvuDfFZ/zvvFdb7S+diU6C0DlstWk+htXlkxWfQPYx0Tlk1WEgdBKsLmP/lCpfZXnULGdmopMgdHY7up/PMs3HEDoR+dBXvYqwgpnONh86DUInQeg7zfTCiuOEToLQScjdGXUXtCk10We63FUxy5knJvosh837pCY6XULfYD/ftvK5CJ2E04duP2eMk4cu8uc7sr5cr9dp1p1Thw4fhE7Caa+jH1lbZvnzyu8x0UkQOglCJ+F0O7pLimwx0UnIh+6KS8NpVhcrC/8nP9FpSIdubek4xeryyNoi8uNWXg/TE50OoZMgdBKW3tHt5nOa8YxNdBKETsKyq4s3VnCEiU7CkqGvfOOC91gu9KMri7Xl9WYcRMuFDo8QOglCJ2Gp0F1SXMdse/pSocOjlgl9tgnBWpa9M/o3Vha2LDPR4SeEToLQ2WX110hCJ0HoJAidhNNdXry3S7r8+N3HmX2czer7+BYTPe6MUW853US/5+v0Kvsa+Zmjv9x5wqeq4befiJXiXyXKN5zp5sFYXW5cLpfpA1rhMd6a5bEutbpcr9eXHNxs680ssaxsqdDHeF3sYwjsTKwuJCwZ+iwrBetYMvQxxM4xy+3ot+7Fbsf+u62ze9Z5zTiElg6d42aM8BWWXV328Eldn907izOf1VJ3Rl9lxpXn1RE+egYT/LJsPnCry+QmCOcUhD4hcT+f0DcI7XxO/WIUPgidBKGTIHQShE6C0EkQOglC52lmvv8gdBKEToLQeYqZ15YxhE6E0EkQOglCJ0HoJAidBKGTIHQShE6C0Plmxs+1+SmhkyB0EoROgtBJEDoJQifBZy/ysNnfbHHLRCdB6CQInU/OeFd0DKETIXQShM5/zrq2jCF0IoROgtBJEDoJQidB6CQInQShkyB0EoROgtBJEDoJQidB6CQInYes9MboMYTOjdXiPULoHLbiL4TQSRA6CULnkxXXkj2EToLQSRA6CT5Nl91W3t9NdL5ZOei/EToJVhc2nW2qm+gkCJ0EoZMgdBKEToLQSRA6CUInQegkCJ0EoZMgdBKEToLQSRA6CUInQegkCJ0EoZMgdBKEToLQSRA6CUInQegkCJ0EoZMgdBKEToLQSRA6CUInQegkCJ0EoZMgdBKEToLQSRA6CUInQegkCJ0EoZMgdBKEToLQSRA6CUInQegkCJ0EoZMgdBKEToLQSfhz5+eXlzwK+GUmOglCJ0HoJAidBKGTIHQS/gVdubkZTqNSBQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "png_dir = '/Users/utoarca/Documents/Pearson_AI/gan_data/synthetic_with_color/with_backgrounds/'\n",
    "png_dir_out = '/Users/utoarca/Documents/Pearson_AI/gan_data/synthetic_with_color/preprocessed/'\n",
    "    # paths = [{'in_': train_path_input, 'out_': output_dir_train_input}, \n",
    "    #          {'in_': train_path_real, 'out_':output_dir_train_real,\n",
    "    #          {'in_': test_path_input, 'out_': output_dir_test_input}, \n",
    "    #          {'in_': test_path_real, 'out_': output_dir_test_real}]\n",
    "\n",
    "paths = [{'in_': png_dir, 'out_': png_dir_out}]\n",
    "        \n",
    "for num in range(0, len(paths)):\n",
    "    # print(paths[num])\n",
    "    for file in tqdm(os.listdir(paths[num]['in_'])):\n",
    "        # print(file)\n",
    "        preprocess(paths[num]['in_'], file, paths[num]['out_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
